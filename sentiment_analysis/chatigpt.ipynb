{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "torch.set_default_device(\"cuda\")\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\"microsoft/phi-1_5\", torch_dtype=\"auto\", trust_remote_code=True)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/phi-1_5\", trust_remote_code=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Столица Америки?\n",
      "\n",
      "A:\n",
      "\n",
      "You can use the following code:\n",
      "import numpy as np\n",
      "\n",
      "a = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
      "\n",
      "print(a)\n",
      "\n",
      "# [[1 2 3]\n",
      "#  [4 5 6]\n",
      "#  [7 8 9]]\n",
      "\n",
      "print(np.sum(a, axis=0))\n",
      "\n",
      "# [12 15 18]\n",
      "\n",
      "print(np.sum(a, axis=1))\n",
      "\n",
      "# [ 6 15 24]\n",
      "\n",
      "print(np.sum(a, axis=2))\n",
      "\n",
      "# [12 15 18]\n",
      "\n",
      "A:\n",
      "\n",
      "You can use np.sum() with axis parameter.\n",
      "import numpy as np\n",
      "\n",
      "a = np.array([[1, 2, 3\n"
     ]
    }
   ],
   "source": [
    "inputs = tokenizer('''Столица Америки?''', return_tensors=\"pt\", return_attention_mask=False)\n",
    "\n",
    "outputs = model.generate(**inputs, max_length=200)\n",
    "text = tokenizer.batch_decode(outputs)[0]\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'The Capital of USA is ___________ A________. A short-term money supply for a large market-based economy, under an elaborate system of'},\n",
       " {'generated_text': 'The Capital of USA is \\xa0a huge capital for the University of California. What is most impressive is\\xa0 the\\xa0 ability of some of these campus'},\n",
       " {'generated_text': \"The Capital of USA is ???? And there is no other place for those of us who know this story better than America's Capital of USA…\\n\"},\n",
       " {'generated_text': \"The Capital of USA is \\xa0familiarized with the world of the Big Oil.\\nWith its history of leading the world's extraction of oil\"},\n",
       " {'generated_text': 'The Capital of USA is \\xa0an all-white nation of roughly 1.5 million people whose economic and cultural capital comes from a diverse range of'}]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import pipeline, set_seed\n",
    "generator = pipeline('text-generation', model='gpt2')\n",
    "set_seed(42)\n",
    "generator(\"The Capital of USA is \", max_length=30, num_return_sequences=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': \"To make pizza you need a good pizza. That's why I'm working with the New York Pizza Kitchen and the New York Pizza Maker Project, to\"},\n",
       " {'generated_text': 'To make pizza you need flour, or baking powder.\\n\\nIn 2 cups of a nonstick skillet, add the tomatoes and carrots. Cook until'},\n",
       " {'generated_text': 'To make pizza you need to get into a groove. That groove starts inside your head, and is the way you keep yourself centered, which makes it'},\n",
       " {'generated_text': 'To make pizza you need this in a bottle or in a container and you can fill everything up with a bit of whatever pie dough you want. The'},\n",
       " {'generated_text': \"To make pizza you need to be able to make it from scratch – I can't tell if they all cook perfectly like this. The crust makes it\"}]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "generator(\"To make pizza you need\", max_length=30, num_return_sequences=5)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
